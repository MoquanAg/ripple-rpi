# Phase 2.6 Production Resilience Testing Design: Infrastructure Failure Discovery

**Date:** 2026-01-30
**Issue:** MOQ-79 Phase 2.6
**System Value:** Â¥100,000 per device
**Goal:** Discover how the system actually handles infrastructure failures through test-only exploration, then create Linear issues for any failures that need fixing

## Overview

Phase 2.6 adds **30-37 production resilience tests** that simulate infrastructure failures to discover actual system behavior:
- Database corruption and lock contention (APScheduler SQLite)
- File system failures (JSON corruption, partial writes, permission errors)
- Hardware connection failures (TCP disconnects, serial errors, intermittent connections)

**Approach:** Test-only discovery pattern. We write comprehensive tests that simulate infrastructure failures, document actual behavior (PASS/FAIL/XFAIL), then create Linear issues for any failures that need fixing. No production code changes in this phase.

**Why Phase 2.6:** Phases 2 and 2.5 validate control logic and safety mechanisms. Phase 2.6 validates that the system survives the real-world infrastructure failures common on Raspberry Pi devices: SD card corruption, power loss during writes, flaky serial connections, and database locks.

## Test Phases Summary

```
Phase 1:   10 tests  - Startup initialization
Phase 2:   39 tests  - Core control logic (nutrient, pH, water level, config, scheduler)
Phase 2.5: 74 tests  - Safety (sensor validation, overdose prevention, system safety)
Phase 2.6: 30-37 tests - Production resilience (infrastructure failure discovery)
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
Total:     153-160 tests
```

---

## Discovery Pattern

Each test follows this structure:

```python
@pytest.mark.resilience
def test_<failure_scenario>():
    """
    Failure Mode: <what breaks>
    Expected Behavior: <what SHOULD happen for a Â¥100,000 device>
    Discovery: <PASS|FAIL|XFAIL - what actually happens>
    Linear Issue: <issue ID if behavior needs fixing>
    """
    # Arrange: inject failure condition
    # Act: trigger the code path that encounters the failure
    # Assert: verify system behavior (graceful degradation, not crash)
```

Tests use `pytest.mark.xfail` for known-bad behavior that needs fixing, with the Linear issue ID in the reason string.

---

## New Test Infrastructure

### Error Injection Fixtures (`tests/fixtures/error_injection.py`)

```python
class FileCorruptor:
    """Inject file system failures for testing"""

    def write_truncated(self, path: str, content: str, truncate_at: int):
        """Simulate power loss during write (partial content)"""

    def write_garbage(self, path: str):
        """Simulate SD card corruption (random bytes)"""

    def make_readonly(self, path: str):
        """Simulate permission error"""

    def make_unreadable(self, path: str):
        """Simulate file gone or inaccessible"""

    def write_empty(self, path: str):
        """Simulate zero-length file (power loss at start of write)"""

    def write_valid_then_corrupt(self, path: str, valid_content: str):
        """Write valid content, then corrupt specific bytes"""


class DatabaseCorruptor:
    """Inject SQLite database failures for testing"""

    def corrupt_header(self, db_path: str):
        """Overwrite SQLite header bytes"""

    def lock_database(self, db_path: str) -> contextmanager:
        """Hold exclusive lock on database file"""

    def truncate_database(self, db_path: str, keep_bytes: int):
        """Simulate power loss during database write"""

    def fill_disk(self, db_path: str) -> contextmanager:
        """Simulate disk full by mounting tmpfs (or mock)"""


class HardwareDisconnector:
    """Inject hardware connection failures for testing"""

    def tcp_refuse_connection(self) -> contextmanager:
        """Simulate lumina-modbus-server not running"""

    def tcp_timeout(self, timeout_seconds: float) -> contextmanager:
        """Simulate lumina-modbus-server hanging"""

    def tcp_partial_response(self, response_bytes: bytes):
        """Simulate truncated TCP response"""

    def tcp_connection_reset(self) -> contextmanager:
        """Simulate connection reset mid-communication"""

    def intermittent_failure(self, fail_rate: float) -> contextmanager:
        """Simulate intermittent connection (fails N% of the time)"""
```

### Directory Structure

```
tests/
â”œâ”€â”€ fixtures/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ conftest.py            # Existing fixtures
â”‚   â””â”€â”€ error_injection.py     # ğŸ†• FileCorruptor, DatabaseCorruptor, HardwareDisconnector
â”œâ”€â”€ unit/                      # Phases 1, 2, 2.5
â”‚   â”œâ”€â”€ test_startup_initialization.py
â”‚   â”œâ”€â”€ test_nutrient_logic.py
â”‚   â”œâ”€â”€ test_config_loading.py
â”‚   â”œâ”€â”€ test_scheduler_persistence.py
â”‚   â”œâ”€â”€ test_ph_logic.py
â”‚   â”œâ”€â”€ test_water_level_logic.py
â”‚   â”œâ”€â”€ test_sensor_validation.py
â”‚   â”œâ”€â”€ test_overdose_prevention.py
â”‚   â””â”€â”€ test_system_safety.py
â””â”€â”€ resilience/                # ğŸ†• Phase 2.6
    â”œâ”€â”€ __init__.py
    â”œâ”€â”€ conftest.py            # ğŸ†• Resilience-specific fixtures
    â”œâ”€â”€ test_database_resilience.py     # ğŸ†• 8-10 tests
    â”œâ”€â”€ test_filesystem_resilience.py   # ğŸ†• 12-15 tests
    â””â”€â”€ test_hardware_resilience.py     # ğŸ†• 10-12 tests
```

---

## Test Details

### File 1: test_database_resilience.py (8-10 tests)

Tests how APScheduler and the system handle SQLite database failures.

**Critical File:** `data/scheduler_jobs.sqlite`

#### Test 1: Corrupted SQLite Header â†’ System Still Starts

```python
@pytest.mark.resilience
def test_corrupted_sqlite_header_system_starts(tmp_path, db_corruptor):
    """
    Failure Mode: SQLite header bytes overwritten (SD card corruption)
    Expected: System starts with fresh scheduler, logs warning
    """
    db_path = tmp_path / "scheduler_jobs.sqlite"
    # Create valid DB, then corrupt header
    create_scheduler_db(db_path)
    db_corruptor.corrupt_header(db_path)

    # System should start despite corrupted DB
    scheduler = init_scheduler(db_path=str(db_path))
    assert scheduler is not None
    assert scheduler.running == True
```

#### Test 2: Completely Missing SQLite â†’ Fresh Start

```python
@pytest.mark.resilience
def test_missing_sqlite_fresh_start(tmp_path):
    """
    Failure Mode: Database file deleted or never created
    Expected: System creates fresh database and starts normally
    """
    db_path = tmp_path / "scheduler_jobs.sqlite"
    assert not db_path.exists()

    scheduler = init_scheduler(db_path=str(db_path))
    assert scheduler is not None
    assert scheduler.running == True
```

#### Test 3: Database Locked by Another Process â†’ Graceful Handling

```python
@pytest.mark.resilience
def test_sqlite_locked_by_another_process(tmp_path, db_corruptor):
    """
    Failure Mode: Another process holds exclusive lock (backup script, crashed instance)
    Expected: System retries or starts with memory-only scheduler, logs error
    """
    db_path = tmp_path / "scheduler_jobs.sqlite"
    create_scheduler_db(db_path)

    with db_corruptor.lock_database(db_path):
        scheduler = init_scheduler(db_path=str(db_path))
        # Should not crash - either retry or fallback
        assert scheduler is not None
```

#### Test 4: Database Truncated (Power Loss During Write)

```python
@pytest.mark.resilience
def test_sqlite_truncated_during_write(tmp_path, db_corruptor):
    """
    Failure Mode: Power loss during SQLite write â†’ truncated file
    Expected: System detects corruption, recreates DB, starts fresh
    """
    db_path = tmp_path / "scheduler_jobs.sqlite"
    create_scheduler_db_with_jobs(db_path, num_jobs=5)
    db_corruptor.truncate_database(db_path, keep_bytes=100)

    scheduler = init_scheduler(db_path=str(db_path))
    assert scheduler is not None
```

#### Test 5: Disk Full â†’ Cannot Write New Jobs

```python
@pytest.mark.resilience
def test_disk_full_cannot_write_jobs(tmp_path, db_corruptor):
    """
    Failure Mode: SD card full, cannot write new scheduler jobs
    Expected: System continues with existing schedule, logs error, does not crash
    """
    db_path = tmp_path / "scheduler_jobs.sqlite"
    create_scheduler_db(db_path)
    scheduler = init_scheduler(db_path=str(db_path))

    with db_corruptor.fill_disk(db_path):
        # Attempt to add a new job
        result = safely_add_job(scheduler, job_func, trigger='interval', seconds=60)
        # Should not crash
        assert scheduler.running == True
```

#### Test 6: Database Permission Denied (Read-Only Filesystem)

```python
@pytest.mark.resilience
def test_sqlite_readonly_filesystem(tmp_path, file_corruptor):
    """
    Failure Mode: Filesystem mounted read-only (SD card protection mode)
    Expected: System starts with memory-only scheduler, logs warning
    """
    db_path = tmp_path / "scheduler_jobs.sqlite"
    create_scheduler_db(db_path)
    file_corruptor.make_readonly(db_path)

    scheduler = init_scheduler(db_path=str(db_path))
    assert scheduler is not None
```

#### Test 7: Rapid Restart Creates Multiple Scheduler Instances

```python
@pytest.mark.resilience
def test_rapid_restart_no_duplicate_jobs(tmp_path):
    """
    Failure Mode: System restarted rapidly (watchdog, crash loop)
    Expected: No duplicate scheduled jobs after restart
    """
    db_path = tmp_path / "scheduler_jobs.sqlite"

    # Start, add jobs, stop
    scheduler1 = init_scheduler(db_path=str(db_path))
    add_standard_jobs(scheduler1)
    job_count_1 = len(scheduler1.get_jobs())
    scheduler1.shutdown()

    # Restart immediately
    scheduler2 = init_scheduler(db_path=str(db_path))
    add_standard_jobs(scheduler2)
    job_count_2 = len(scheduler2.get_jobs())

    # Should not have duplicate jobs
    assert job_count_2 == job_count_1
```

#### Test 8: WAL File Corruption

```python
@pytest.mark.resilience
def test_sqlite_wal_corruption(tmp_path, db_corruptor):
    """
    Failure Mode: SQLite WAL (Write-Ahead Log) file corrupted
    Expected: System recovers from main DB file, logs warning
    """
    db_path = tmp_path / "scheduler_jobs.sqlite"
    create_scheduler_db_with_jobs(db_path, num_jobs=3)

    # Corrupt WAL file if it exists
    wal_path = tmp_path / "scheduler_jobs.sqlite-wal"
    if wal_path.exists():
        db_corruptor.corrupt_header(wal_path)

    scheduler = init_scheduler(db_path=str(db_path))
    assert scheduler is not None
```

---

### File 2: test_filesystem_resilience.py (12-15 tests)

Tests how the system handles corrupted, missing, or inaccessible configuration and data files.

#### JSON Data Files

**Critical Files:**
- `data/saved_sensor_data.json` - Current sensor readings
- `data/runtime_tracker_history.json` - Dosing runtime tracking
- `config/action.json` - Manual relay commands

#### Test 9: Sensor Data JSON Truncated (Partial Write)

```python
@pytest.mark.resilience
def test_sensor_data_json_truncated(tmp_path, file_corruptor):
    """
    Failure Mode: Power loss during sensor data save â†’ partial JSON
    Expected: System uses default/empty sensor data, logs warning, continues
    """
    sensor_file = tmp_path / "saved_sensor_data.json"
    valid_data = '{"ec": 1.2, "ph": 6.5, "water_level": 80}'
    file_corruptor.write_truncated(sensor_file, valid_data, truncate_at=20)
    # File now contains: '{"ec": 1.2, "ph": 6.'  (invalid JSON)

    result = load_sensor_data(str(sensor_file))
    assert result is not None  # Should not crash
    # Should return defaults or empty, not raise
```

#### Test 10: Sensor Data JSON Contains Garbage

```python
@pytest.mark.resilience
def test_sensor_data_json_garbage(tmp_path, file_corruptor):
    """
    Failure Mode: SD card sector corruption â†’ random bytes in file
    Expected: System uses default sensor data, logs error
    """
    sensor_file = tmp_path / "saved_sensor_data.json"
    file_corruptor.write_garbage(sensor_file)

    result = load_sensor_data(str(sensor_file))
    assert result is not None
```

#### Test 11: Sensor Data JSON Missing Entirely

```python
@pytest.mark.resilience
def test_sensor_data_json_missing(tmp_path):
    """
    Failure Mode: File never created or deleted
    Expected: System starts with empty/default sensor data
    """
    sensor_file = tmp_path / "saved_sensor_data.json"
    assert not sensor_file.exists()

    result = load_sensor_data(str(sensor_file))
    assert result is not None
```

#### Test 12: Sensor Data JSON Empty File

```python
@pytest.mark.resilience
def test_sensor_data_json_empty(tmp_path, file_corruptor):
    """
    Failure Mode: Power loss at start of write â†’ zero-length file
    Expected: System uses defaults, does not crash on empty JSON parse
    """
    sensor_file = tmp_path / "saved_sensor_data.json"
    file_corruptor.write_empty(sensor_file)

    result = load_sensor_data(str(sensor_file))
    assert result is not None
```

#### Test 13: Runtime Tracker JSON Corrupted

```python
@pytest.mark.resilience
def test_runtime_tracker_json_corrupted(tmp_path, file_corruptor):
    """
    Failure Mode: runtime_tracker_history.json corrupted
    Expected: System resets runtime tracking (conservative: allows dosing)
    """
    tracker_file = tmp_path / "runtime_tracker_history.json"
    file_corruptor.write_garbage(tracker_file)

    tracker = load_runtime_tracker(str(tracker_file))
    # Should start fresh - no accumulated runtime
    assert tracker.get_today_total_runtime() == 0
```

#### Test 14: Runtime Tracker JSON Partial Write

```python
@pytest.mark.resilience
def test_runtime_tracker_partial_write(tmp_path, file_corruptor):
    """
    Failure Mode: Power loss during runtime tracker save
    Expected: System resets tracking, logs warning
    """
    tracker_file = tmp_path / "runtime_tracker_history.json"
    valid_data = '{"2026-01-30": {"total_seconds": 1800, "events": []}}'
    file_corruptor.write_truncated(tracker_file, valid_data, truncate_at=30)

    tracker = load_runtime_tracker(str(tracker_file))
    assert tracker is not None
```

#### Test 15: action.json Corrupted â†’ No Manual Commands Execute

```python
@pytest.mark.resilience
def test_action_json_corrupted(tmp_path, file_corruptor):
    """
    Failure Mode: action.json contains invalid JSON
    Expected: System ignores manual commands, logs error, continues automatic operation
    """
    action_file = tmp_path / "action.json"
    file_corruptor.write_garbage(action_file)

    result = load_action_config(str(action_file))
    # Should not crash, should return empty/default actions
    assert result is not None
```

#### Test 16: action.json Missing â†’ System Continues Without Manual Commands

```python
@pytest.mark.resilience
def test_action_json_missing(tmp_path):
    """
    Failure Mode: action.json deleted or never created
    Expected: System operates in automatic mode only
    """
    action_file = tmp_path / "action.json"
    assert not action_file.exists()

    result = load_action_config(str(action_file))
    assert result is not None
```

#### INI Config File (device.conf)

#### Test 17: device.conf Truncated

```python
@pytest.mark.resilience
def test_device_conf_truncated(tmp_path, file_corruptor):
    """
    Failure Mode: Power loss during config write â†’ partial INI file
    Expected: System uses defaults for missing sections, logs warning
    """
    config_file = tmp_path / "device.conf"
    valid_config = """[SYSTEM]
username = admin
password = admin

[NutrientPump]
nutrient_pump_on_duration = 00:00:10, 00:00:15
"""
    file_corruptor.write_truncated(config_file, valid_config, truncate_at=40)

    config = load_device_config(str(config_file))
    assert config is not None
```

#### Test 18: device.conf Contains Invalid INI Syntax

```python
@pytest.mark.resilience
def test_device_conf_invalid_ini(tmp_path):
    """
    Failure Mode: Config file has corrupt INI syntax (no section headers, binary data)
    Expected: System uses all defaults, logs error
    """
    config_file = tmp_path / "device.conf"
    config_file.write_text("this is not\nvalid INI\nformat at all\n\x00\x01\x02")

    config = load_device_config(str(config_file))
    assert config is not None
```

#### Test 19: device.conf Permission Denied

```python
@pytest.mark.resilience
def test_device_conf_unreadable(tmp_path, file_corruptor):
    """
    Failure Mode: File permissions changed (security update, admin error)
    Expected: System uses defaults, logs error, continues
    """
    config_file = tmp_path / "device.conf"
    config_file.write_text("[SYSTEM]\nusername = admin\n")
    file_corruptor.make_unreadable(config_file)

    config = load_device_config(str(config_file))
    assert config is not None
```

#### Test 20: device.conf Missing Entirely

```python
@pytest.mark.resilience
def test_device_conf_missing(tmp_path):
    """
    Failure Mode: Config file deleted or never deployed
    Expected: System starts with all defaults, logs error
    """
    config_file = tmp_path / "device.conf"
    assert not config_file.exists()

    config = load_device_config(str(config_file))
    assert config is not None
```

#### Write Safety

#### Test 21: Save Sensor Data During Disk Full

```python
@pytest.mark.resilience
def test_save_sensor_data_disk_full(tmp_path, db_corruptor):
    """
    Failure Mode: Cannot save sensor data (disk full)
    Expected: System continues operating, logs error, does not crash
    """
    sensor_file = tmp_path / "saved_sensor_data.json"

    with db_corruptor.fill_disk(sensor_file):
        # Attempt to save sensor data
        result = save_sensor_data(str(sensor_file), {"ec": 1.2, "ph": 6.5})
        # Should not crash - operation continues even if save fails
```

#### Test 22: Concurrent File Access (Hot-Reload vs Save)

```python
@pytest.mark.resilience
def test_concurrent_config_read_write(tmp_path):
    """
    Failure Mode: Watchdog hot-reload reads config while system is writing
    Expected: No partial reads, no crashes
    """
    config_file = tmp_path / "device.conf"
    config_file.write_text("[SYSTEM]\nusername = admin\n")

    # Simulate concurrent access
    import threading
    errors = []

    def writer():
        for _ in range(100):
            try:
                save_device_config(str(config_file), {"SYSTEM": {"username": "admin"}})
            except Exception as e:
                errors.append(e)

    def reader():
        for _ in range(100):
            try:
                load_device_config(str(config_file))
            except Exception as e:
                errors.append(e)

    t1 = threading.Thread(target=writer)
    t2 = threading.Thread(target=reader)
    t1.start()
    t2.start()
    t1.join()
    t2.join()

    assert len(errors) == 0, f"Concurrent access errors: {errors}"
```

#### Test 23: Atomic Write Verification

```python
@pytest.mark.resilience
def test_sensor_data_atomic_write(tmp_path):
    """
    Failure Mode: Non-atomic write leaves partial data on crash
    Expected: System uses write-then-rename (atomic) pattern
    Discovery: Check if system uses temp file + rename for critical writes
    """
    sensor_file = tmp_path / "saved_sensor_data.json"
    sensor_file.write_text('{"ec": 1.0}')

    # Save new data
    save_sensor_data(str(sensor_file), {"ec": 1.5, "ph": 6.5})

    # Verify file is valid JSON (not partial)
    import json
    with open(sensor_file) as f:
        data = json.load(f)
    assert "ec" in data
```

---

### File 3: test_hardware_resilience.py (10-12 tests)

Tests how the system handles lumina-modbus-server and serial communication failures.

#### TCP Connection Failures

#### Test 24: lumina-modbus-server Not Running â†’ Connection Refused

```python
@pytest.mark.resilience
def test_modbus_server_not_running(hw_disconnector):
    """
    Failure Mode: lumina-modbus-server crashed or not started
    Expected: System starts, logs error, retries connection, operates in degraded mode
    """
    with hw_disconnector.tcp_refuse_connection():
        client = create_modbus_client()
        # Should not crash - should handle ConnectionRefusedError
        result = client.read_sensor(sensor_addr=0x02)
        assert result is None or result == {}
```

#### Test 25: lumina-modbus-server Hangs â†’ TCP Timeout

```python
@pytest.mark.resilience
def test_modbus_server_hangs(hw_disconnector):
    """
    Failure Mode: lumina-modbus-server accepts connection but stops responding
    Expected: Client times out, does not block forever, system continues
    """
    with hw_disconnector.tcp_timeout(timeout_seconds=30):
        client = create_modbus_client()
        # Should timeout, not hang forever
        result = client.read_sensor(sensor_addr=0x02)
        # Verify it returned within reasonable time (not 30+ seconds)
        assert result is None or result == {}
```

#### Test 26: TCP Connection Reset During Read

```python
@pytest.mark.resilience
def test_tcp_connection_reset_during_read(hw_disconnector):
    """
    Failure Mode: TCP connection reset mid-communication (network issue, server crash)
    Expected: System handles ConnectionResetError, retries or degrades gracefully
    """
    with hw_disconnector.tcp_connection_reset():
        client = create_modbus_client()
        result = client.read_sensor(sensor_addr=0x02)
        assert result is None or result == {}
```

#### Test 27: Partial TCP Response (Truncated Modbus Frame)

```python
@pytest.mark.resilience
def test_partial_tcp_response(hw_disconnector):
    """
    Failure Mode: TCP connection drops mid-response â†’ partial Modbus frame
    Expected: Client detects incomplete frame, retries or returns error
    """
    # Simulate partial 3-byte response (valid Modbus response is longer)
    hw_disconnector.tcp_partial_response(response_bytes=b'\x02\x03\x04')

    client = create_modbus_client()
    result = client.read_sensor(sensor_addr=0x02)
    # Should not crash on partial data
    assert result is None or result == {}
```

#### Test 28: Server Reconnection After Disconnect

```python
@pytest.mark.resilience
def test_modbus_server_reconnection(hw_disconnector, mock_modbus_server):
    """
    Failure Mode: Server goes down then comes back up
    Expected: Client automatically reconnects and resumes operation
    """
    client = create_modbus_client()

    # Read works initially
    result1 = client.read_sensor(sensor_addr=0x02)
    assert result1 is not None

    # Server goes down
    with hw_disconnector.tcp_refuse_connection():
        result2 = client.read_sensor(sensor_addr=0x02)
        assert result2 is None or result2 == {}

    # Server comes back up
    result3 = client.read_sensor(sensor_addr=0x02)
    assert result3 is not None  # Should reconnect automatically
```

#### Sensor Read Failures

#### Test 29: Sensor Returns No Response (Modbus Timeout)

```python
@pytest.mark.resilience
def test_sensor_no_response(mock_modbus_client):
    """
    Failure Mode: Sensor hardware disconnected, no Modbus response
    Expected: System logs timeout, marks sensor as unavailable, continues
    """
    mock_modbus_client.read_sensor.return_value = None  # Timeout

    # System should handle missing sensor data
    result = read_all_sensors()
    assert result is not None
    # Specific sensor should be marked unavailable, not crash
```

#### Test 30: Sensor Returns Invalid Modbus Frame

```python
@pytest.mark.resilience
def test_sensor_invalid_modbus_frame(mock_modbus_client):
    """
    Failure Mode: Sensor returns garbage data (hardware malfunction)
    Expected: System rejects invalid frame, logs error, retries
    """
    mock_modbus_client.read_sensor.return_value = b'\xff\xff\xff\xff'

    result = read_all_sensors()
    assert result is not None
```

#### Test 31: Intermittent Sensor Failure (50% Failure Rate)

```python
@pytest.mark.resilience
def test_intermittent_sensor_failure(hw_disconnector):
    """
    Failure Mode: Loose connection causes intermittent read failures
    Expected: System retries, uses last known good value, logs warnings
    """
    with hw_disconnector.intermittent_failure(fail_rate=0.5):
        results = []
        for _ in range(10):
            result = read_sensor(sensor_addr=0x02)
            results.append(result)

        # Some reads should succeed despite 50% failure rate
        successful = [r for r in results if r is not None]
        assert len(successful) > 0
```

#### Relay Control Failures

#### Test 32: Relay Command Send Fails â†’ Safe State

```python
@pytest.mark.resilience
def test_relay_command_send_fails(hw_disconnector):
    """
    Failure Mode: Cannot send relay command (TCP connection lost)
    Expected: System assumes worst-case (pump may be ON), triggers safety check
    """
    with hw_disconnector.tcp_refuse_connection():
        result = send_relay_command(relay_addr=0x01, channel=1, state=False)
        # Should not crash
        # Should flag that relay state is unknown
        assert result.success == False or result is None
```

#### Test 33: Relay State Read Fails â†’ Assume Unsafe

```python
@pytest.mark.resilience
def test_relay_state_read_fails(hw_disconnector):
    """
    Failure Mode: Cannot read relay state for verification
    Expected: System assumes unsafe (relay may be stuck ON), logs error
    """
    with hw_disconnector.tcp_refuse_connection():
        state = read_relay_state(relay_addr=0x01, channel=1)
        # Should return None/unknown, not crash
        assert state is None or state == "unknown"
```

#### Test 34: Multiple Hardware Failures Simultaneously

```python
@pytest.mark.resilience
def test_multiple_hardware_failures(hw_disconnector):
    """
    Failure Mode: Both sensor port and relay port fail (power supply issue)
    Expected: System enters safe degraded mode, all dosing stopped
    """
    with hw_disconnector.tcp_refuse_connection():
        # Both sensor reads and relay commands fail
        sensors = read_all_sensors()
        relay_result = send_relay_command(relay_addr=0x01, channel=1, state=False)

        # System should not crash
        assert sensors is not None or sensors == {}
```

#### Test 35: Long-Running Connection Degradation

```python
@pytest.mark.resilience
def test_connection_degradation_over_time(hw_disconnector):
    """
    Failure Mode: Connection quality degrades (increasing timeouts, partial failures)
    Expected: System detects degradation pattern, logs warnings
    """
    # Simulate increasing failure rate
    for fail_rate in [0.1, 0.3, 0.5, 0.7]:
        with hw_disconnector.intermittent_failure(fail_rate=fail_rate):
            result = read_sensor(sensor_addr=0x02)
            # Should handle gracefully at each degradation level
```

---

## Implementation Requirements

### New Files to Create

| File | Purpose |
|------|---------|
| `tests/fixtures/error_injection.py` | FileCorruptor, DatabaseCorruptor, HardwareDisconnector classes |
| `tests/resilience/__init__.py` | Package marker |
| `tests/resilience/conftest.py` | Resilience-specific pytest fixtures |
| `tests/resilience/test_database_resilience.py` | 8-10 SQLite/APScheduler tests |
| `tests/resilience/test_filesystem_resilience.py` | 12-15 JSON/INI file tests |
| `tests/resilience/test_hardware_resilience.py` | 10-12 TCP/Modbus/serial tests |

### No Production Code Changes

Phase 2.6 is discovery-only. Tests exercise existing code paths. Any discovered failures become Linear issues for future phases.

### pytest Configuration

```ini
# pytest markers
[tool.pytest.ini_options]
markers = [
    "resilience: Phase 2.6 production resilience tests",
]
```

---

## Success Criteria

### Discovery Goals
- **30-37 tests** covering all three resilience areas
- Each test documents actual system behavior (PASS/FAIL/XFAIL)
- Every FAIL/XFAIL creates a corresponding Linear issue
- Tests run in CI without hardware dependencies

### Expected Outcome Distribution
- **PASS (40-60%):** System already handles the failure correctly
- **XFAIL (30-40%):** Known gaps that need fixing (tracked in Linear)
- **FAIL (0-10%):** Unexpected crashes that need urgent fixing

### Coverage Areas
| Area | Tests | Critical Files |
|------|-------|---------------|
| Database Resilience | 8-10 | scheduler_jobs.sqlite |
| File System Resilience | 12-15 | saved_sensor_data.json, device.conf, action.json, runtime_tracker_history.json |
| Hardware Connection | 10-12 | LuminaModbusClient TCP, sensor reads, relay commands |

---

## Risk Matrix (What Phase 2.6 Discovers)

| Failure Mode | Without Phase 2.6 | With Phase 2.6 |
|----|---|---|
| SQLite corrupted on SD card | â“ Unknown - may crash on startup | âœ… Documented behavior, fix tracked |
| Power loss during JSON save | â“ Unknown - may lose all sensor data | âœ… Discovered if atomic writes used |
| lumina-modbus-server down | â“ Unknown - may hang forever | âœ… Timeout and degradation tested |
| Sensor loose connection | â“ Unknown - may cause erratic dosing | âœ… Intermittent failure handling known |
| Read-only filesystem | â“ Unknown - may crash | âœ… Graceful degradation verified |
| device.conf corrupted | â“ Unknown - may use unsafe defaults | âœ… Default handling documented |
| Relay command fails | â“ Unknown - pump state unknown | âœ… Fail-safe behavior verified |
| Multiple simultaneous failures | â“ Unknown - cascading crash risk | âœ… Combined failure modes tested |

---

## Implementation Order

1. **Error injection fixtures** (`tests/fixtures/error_injection.py`)
2. **Resilience test infrastructure** (`tests/resilience/conftest.py`)
3. **Database resilience tests** (8-10 tests)
4. **File system resilience tests** (12-15 tests)
5. **Hardware resilience tests** (10-12 tests)
6. **Run all tests, document results** (PASS/FAIL/XFAIL)
7. **Create Linear issues** for all FAIL/XFAIL results

---

## Notes

- Phase 2.6 is **discovery-only** - no production code changes
- Tests use `pytest.mark.xfail(reason="MOQ-XXX: description")` for known failures
- All tests must run without real hardware (mock/inject only)
- Tests should complete quickly (no real network timeouts - use mocked timeouts)
- SD card failure is the #1 Raspberry Pi reliability risk in the field
- This phase informs the Phase 3 hardening roadmap
